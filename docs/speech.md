# Architectures for speech

En este bloque se aborda brevemente el estudio de algunos modelos neuronales utilizados para procesar voz. El profesor de este bloque es Juan Antonio P√©rez Ortiz. 

Los materiales de clase complementan la lectura de algunos cap√≠tulos de un libro de texto ("Speech and Language Processing" de Dan Jurafsky y James H. Martin, borrador de la tercera edici√≥n, disponible online) con anotaciones realizadas por el profesor.

## Primera sesi√≥n de este bloque (19 de enero de 2024)

### Contenidos a preparar antes de la sesi√≥n del 19/01/2024

Las actividades a realizar antes de esta clase son:

- Lectura y estudio de los contenidos de [esta p√°gina](https://dlsi.ua.es/~japerez/materials/transformers/speech/) sobre reconocimiento de voz. Como ver√°s, la p√°gina te indica qu√© contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo prop√≥sito es ayudarte a entender los conceptos clave del cap√≠tulo. Despu√©s, realiza una segunda lectura del cap√≠tulo del libro. Tras acabar con esta parte, lee la descripci√≥n de [arquitecturas modernas](https://dlsi.ua.es/~japerez/materials/transformers/speech/#arquitecturas-modernas-para-el-procesamiento-de-voz) concretas para el reconocimiento de voz. En total, esta parte deber√≠a llevarte unas 4 horas üïíÔ∏è de trabajo.
- Despu√©s, realiza este [test de evaluaci√≥n](https://forms.gle/woGk9hkmepMVkrg47) de estos contenidos. Son pocas preguntas (menos que en tests anteriores, de hecho) y te llevar√° unos minutos.

### Contenidos para la sesi√≥n presencial del 19/01/2024

En la clase presencial (2,5 horas üïíÔ∏è de duraci√≥n), veremos c√≥mo se implementa un sencillo sistema de reconocimiento de voz en PyTorch. <a href="https://colab.research.google.com/github/jaspock/me/blob/main/docs/materials/transformers/assets/notebooks/speeeeech.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab\"></a>
